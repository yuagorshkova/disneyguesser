{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ü§™–ø—Ä–æ–±—ã –º–æ–¥–µ–ª–µ–π.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8rAicNaoUtg"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km0DXzbwegvm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349c3478-e046-41c6-fce6-f1be7c8386b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3F3-6OeoeIl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l8fyWjTnNGC"
      },
      "source": [
        "data = pd.read_csv('/content/gdrive/MyDrive/Kaggle/Copy of princess_corpus.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM_CCy8aom7l",
        "outputId": "7e75e10f-3e46-462b-ac74-df057e0fd7ea"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7748, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "lyO8fJX8pjXE",
        "outputId": "20426c87-4b48-446e-aa46-7feecc8a13a7"
      },
      "source": [
        "data.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Disney_Period</th>\n",
              "      <th>Text</th>\n",
              "      <th>Speaker_Status</th>\n",
              "      <th>Movie</th>\n",
              "      <th>Speaker</th>\n",
              "      <th>Year</th>\n",
              "      <th>UTTERANCE_NUMBER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>slave in the magic mirror come from the farthe...</td>\n",
              "      <td>NON-P</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>queen</td>\n",
              "      <td>1937</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>what wouldst thou know, my queen ?</td>\n",
              "      <td>NON-P</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>mirror</td>\n",
              "      <td>1937</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Disney_Period  ... UTTERANCE_NUMBER\n",
              "0         EARLY  ...                1\n",
              "1         EARLY  ...                2\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "r9PR0mkIvcRz",
        "outputId": "05c11ce8-25c5-41a0-9000-e6e5fe7ef313"
      },
      "source": [
        "data[data[\"Movie\"]==\"Snow White \"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Disney_Period</th>\n",
              "      <th>Text</th>\n",
              "      <th>Speaker_Status</th>\n",
              "      <th>Movie</th>\n",
              "      <th>Speaker</th>\n",
              "      <th>Year</th>\n",
              "      <th>UTTERANCE_NUMBER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>slave in the magic mirror come from the farthe...</td>\n",
              "      <td>NON-P</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>queen</td>\n",
              "      <td>1937</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>what wouldst thou know, my queen ?</td>\n",
              "      <td>NON-P</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>mirror</td>\n",
              "      <td>1937</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>magic mirror on the wall, who is the fairest o...</td>\n",
              "      <td>NON-P</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>queen</td>\n",
              "      <td>1937</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>famed is thy beauty, majesty. but hold, a love...</td>\n",
              "      <td>NON-P</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>mirror</td>\n",
              "      <td>1937</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>alas for her ! reveal her name.</td>\n",
              "      <td>NON-P</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>queen</td>\n",
              "      <td>1937</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>one song</td>\n",
              "      <td>PRINCE</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>prince</td>\n",
              "      <td>1937</td>\n",
              "      <td>362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>one song, i have but one song one song, only f...</td>\n",
              "      <td>NON-P</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>chorus</td>\n",
              "      <td>1937</td>\n",
              "      <td>363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>goodbye. goodbye, grumpy.</td>\n",
              "      <td>PRINCESS</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>snow white</td>\n",
              "      <td>1937</td>\n",
              "      <td>364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>oh, dopey. goodbye !</td>\n",
              "      <td>NON-P</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>goodbye.</td>\n",
              "      <td>1937</td>\n",
              "      <td>365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>EARLY</td>\n",
              "      <td>some day when spring is here we'll find our lo...</td>\n",
              "      <td>NON-P</td>\n",
              "      <td>Snow White</td>\n",
              "      <td>chorus</td>\n",
              "      <td>1937</td>\n",
              "      <td>366</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>366 rows √ó 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Disney_Period  ... UTTERANCE_NUMBER\n",
              "0           EARLY  ...                1\n",
              "1           EARLY  ...                2\n",
              "2           EARLY  ...                3\n",
              "3           EARLY  ...                4\n",
              "4           EARLY  ...                5\n",
              "..            ...  ...              ...\n",
              "361         EARLY  ...              362\n",
              "362         EARLY  ...              363\n",
              "363         EARLY  ...              364\n",
              "364         EARLY  ...              365\n",
              "365         EARLY  ...              366\n",
              "\n",
              "[366 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IMe1kqVo4y_",
        "outputId": "9fcc9002-5b45-484c-ba0f-01376d119fa6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('russian')\n",
        "\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer('russian')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGv1aQNnp9gY",
        "outputId": "58cc7a0d-e051-43a1-8c6d-a2451d08f2ca"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def custom_lemmatizer(text):\n",
        "  return [lemmatizer.lemmatize(w) for w in word_tokenize(text.lower(), language='russian') if w.isalpha() and not w in sw]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OI4MoMpopjH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaXdB_nZpbHN",
        "outputId": "de67e0a5-9c6f-4fd5-9564-76636087f9d6"
      },
      "source": [
        "print(*custom_tokenizer(data.Text[0]))\n",
        "print(*custom_lemmatizer(data.Text[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "slav in the magic mirror com from the farthest spac through wind and darkness i summon the speak let me se thy fac\n",
            "slave in the magic mirror come from the farthest space through wind and darkness i summon thee speak let me see thy face\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6s7om_LqwE2"
      },
      "source": [
        "index = ((\"phrase\", \"lem\"), (\"phrase\", \"stem\"), (\"sentence\", \"lem\"), (\"sentence\", \"stem\"))\n",
        "train_res = pd.DataFrame(index=index,\n",
        "                  columns=[\"countvec\", \"tf-idf\", \"hashing\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIpEFdgr1rJO"
      },
      "source": [
        "test_res = pd.DataFrame(index=index,\n",
        "                        columns=[\"countvec\", \"tf-idf\", \"hashing\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ywtbFQOzHEs"
      },
      "source": [
        "index = ((\"phrase\", \"lem\", \"train\"), (\"phrase\", \"lem\", \"test\"), (\"phrase\", \"stem\", \"train\"), (\"phrase\", \"stem\", \"test\"), \n",
        "         (\"sentence\", \"lem\", \"train\"), (\"sentence\", \"lem\", \"test\"), (\"sentence\", \"stem\", \"train\"), (\"sentence\", \"stem\", \"train\"))\n",
        "res = pd.DataFrame(index=index,\n",
        "                  columns=[\"countvec\", \"tf-idf\", \"hashing\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e5G-JuauACx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[\"Text\"], data[\"Speaker_Status\"],  test_size = 0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6t_QcB46hu2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7YWJLDL2Cu4"
      },
      "source": [
        "## Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sSM4arotg2v"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cntvec = CountVectorizer(tokenizer=custom_tokenizer)\n",
        "train_cntvec = cntvec.fit_transform(X_train)\n",
        "test_cntvec = cntvec.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS2qJQdnwIJu",
        "outputId": "2f9b3dcd-8c9b-4228-da57-e75dadf5deca"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "clf = SGDClassifier(random_state=0)\n",
        "clf.fit(train_cntvec, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65g0uLvlwKiI"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train_res.loc[\"phrase\", \"stem\"].at[\"countvec\"] = np.round(accuracy_score(clf.predict(train_cntvec), y_train), decimals=3)\n",
        "\n",
        "test_res.loc[\"phrase\", \"stem\"].at[\"countvec\"] = np.round(accuracy_score(clf.predict(test_cntvec), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQkVOXbX4y5c"
      },
      "source": [
        "cntvec1 = CountVectorizer(tokenizer=custom_lemmatizer)\n",
        "train_cntvec = cntvec1.fit_transform(X_train)\n",
        "test_cntvec = cntvec1.transform(X_test)\n",
        "\n",
        "clf = SGDClassifier(random_state=0)\n",
        "clf.fit(train_cntvec, y_train)\n",
        "\n",
        "train_res.loc[\"phrase\", \"lem\"].at[\"countvec\"] = np.round(accuracy_score(clf.predict(train_cntvec), y_train), decimals=3)\n",
        "test_res.loc[\"phrase\", \"lem\"].at[\"countvec\"] = np.round(accuracy_score(clf.predict(test_cntvec), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNpbdRov6W96"
      },
      "source": [
        "cntvec3 = CountVectorizer(tokenizer=custom_tokenizer)\n",
        "train_cntvec = cntvec3.fit_transform(X_train)\n",
        "test_cntvec = cntvec3.transform(X_test)\n",
        "\n",
        "clf = SGDClassifier(random_state=0)\n",
        "clf.fit(train_cntvec, y_train)\n",
        "\n",
        "train_res.loc[\"phrase\", \"lem\"].at[\"countvec\"] = np.round(accuracy_score(clf.predict(train_cntvec), y_train), decimals=3)\n",
        "test_res.loc[\"phrase\", \"lem\"].at[\"countvec\"] = np.round(accuracy_score(clf.predict(test_cntvec), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ux0nKhg2H7q"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9ZUtTb42HK_"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=custom_tokenizer, max_df=.9)\n",
        "train_tfidf = tfidf.fit_transform(X_train)\n",
        "test_tfidf = tfidf.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmQwo9Ew2Vy0",
        "outputId": "d38beb62-1883-4e35-fce2-659da2557649"
      },
      "source": [
        "clf1 = SGDClassifier(random_state=0)\n",
        "clf1.fit(train_tfidf, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlPn4I8d2cmR"
      },
      "source": [
        "train_res.loc[\"phrase\", \"stem\"].at[\"tf-idf\"] = np.round(accuracy_score(clf1.predict(train_tfidf), y_train), decimals=3)\n",
        "\n",
        "test_res.loc[\"phrase\", \"stem\"].at[\"tf-idf\"] = np.round(accuracy_score(clf1.predict(test_tfidf), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EZlnKm55Wk6"
      },
      "source": [
        "tfidf1 = TfidfVectorizer(tokenizer=custom_lemmatizer, max_df=.9)\n",
        "train_tfidf = tfidf1.fit_transform(X_train)\n",
        "test_tfidf = tfidf1.transform(X_test)\n",
        "\n",
        "clf1 = SGDClassifier(random_state=0)\n",
        "clf1.fit(train_tfidf, y_train)\n",
        "\n",
        "train_res.loc[\"phrase\", \"lem\"].at[\"tf-idf\"] = np.round(accuracy_score(clf1.predict(train_tfidf), y_train), decimals=3)\n",
        "test_res.loc[\"phrase\", \"lem\"].at[\"tf-idf\"] = np.round(accuracy_score(clf1.predict(test_tfidf), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTaxWW483Jq8"
      },
      "source": [
        "## Hashing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEiNfc0X3MVt",
        "outputId": "200df3a4-1271-46e2-bc75-595f38aa2f8d"
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "hash_vec = HashingVectorizer(tokenizer=custom_tokenizer, n_features=10000)\n",
        "train_hash = hash_vec.fit_transform(X_train)\n",
        "test_hash = hash_vec.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BfYyR2I3Vaa",
        "outputId": "b47fcf18-a50e-4686-940a-a16cd9e2a06f"
      },
      "source": [
        "clf2 = SGDClassifier(random_state=0)\n",
        "clf2.fit(train_hash, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=0, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMgXKVK-3wre"
      },
      "source": [
        "train_res.loc[\"phrase\", \"stem\"].at[\"hashing\"] = np.round(accuracy_score(clf2.predict(train_hash), y_train), decimals=3)\n",
        "\n",
        "test_res.loc[\"phrase\", \"stem\"].at[\"hashing\"] = np.round(accuracy_score(clf2.predict(test_hash), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma6qLbcj62T1",
        "outputId": "ed7f36ad-d2d5-49ee-ad60-b6751e25a9b4"
      },
      "source": [
        "hash_vec1 = HashingVectorizer(tokenizer=custom_lemmatizer, n_features=10000)\n",
        "train_hash = hash_vec1.fit_transform(X_train)\n",
        "test_hash = hash_vec1.transform(X_test)\n",
        "\n",
        "clf2 = SGDClassifier(random_state=0)\n",
        "clf2.fit(train_hash, y_train)\n",
        "\n",
        "train_res.loc[\"phrase\", \"lem\"].at[\"hashing\"] = np.round(accuracy_score(clf2.predict(train_hash), y_train), decimals=3)\n",
        "test_res.loc[\"phrase\", \"lem\"].at[\"hashing\"] = np.round(accuracy_score(clf2.predict(test_hash), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "gFe3PLsA6EIA",
        "outputId": "b571a8a4-e1d7-4369-9d52-205e8c688c65"
      },
      "source": [
        "train_res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>countvec</th>\n",
              "      <th>tf-idf</th>\n",
              "      <th>hashing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">phrase</th>\n",
              "      <th>lem</th>\n",
              "      <td>0.848</td>\n",
              "      <td>0.804</td>\n",
              "      <td>0.751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem</th>\n",
              "      <td>0.846</td>\n",
              "      <td>0.806</td>\n",
              "      <td>0.746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">sentence</th>\n",
              "      <th>lem</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              countvec tf-idf hashing\n",
              "phrase   lem     0.848  0.804   0.751\n",
              "         stem    0.846  0.806   0.746\n",
              "sentence lem       NaN    NaN     NaN\n",
              "         stem      NaN    NaN     NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "PMh9e2wh4VS8",
        "outputId": "2cd858f7-1907-4a87-c46a-e676998bcf1f"
      },
      "source": [
        "test_res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>countvec</th>\n",
              "      <th>tf-idf</th>\n",
              "      <th>hashing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">phrase</th>\n",
              "      <th>lem</th>\n",
              "      <td>0.622</td>\n",
              "      <td>0.651</td>\n",
              "      <td>0.657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.652</td>\n",
              "      <td>0.656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">sentence</th>\n",
              "      <th>lem</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              countvec tf-idf hashing\n",
              "phrase   lem     0.622  0.651   0.657\n",
              "         stem     0.62  0.652   0.656\n",
              "sentence lem       NaN    NaN     NaN\n",
              "         stem      NaN    NaN     NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkSVoExE7iFK"
      },
      "source": [
        "# –ü–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pggCuBbH8F3w"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVHRehVE8O8l"
      },
      "source": [
        "sents = sum([nltk.sent_tokenize(x) for x in data.Text], [])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRiC16iU-K-3",
        "outputId": "65d03da2-e70f-439d-d2fe-cddf330fca36"
      },
      "source": [
        "len(sents)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13823"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppNI7xN2FKbn",
        "outputId": "dbe53eab-730c-4cbf-abee-061d183fe9a5"
      },
      "source": [
        "sents[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['slave in the magic mirror come from the farthest space through wind and darkness i summon thee.',\n",
              " 'speak !',\n",
              " 'let me see thy face.',\n",
              " 'what wouldst thou know, my queen ?',\n",
              " 'magic mirror on the wall, who is the fairest one of all ?',\n",
              " 'famed is thy beauty, majesty.',\n",
              " 'but hold, a lovely maid i see.',\n",
              " 'rags cannot hide her gentle grace.',\n",
              " 'alas, she is more fair than thee.',\n",
              " 'alas for her !']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hrBI5Qb-682"
      },
      "source": [
        "data[\"n_sent\"] = data[\"Text\"].apply(lambda x: len(nltk.sent_tokenize(x)))\n",
        "data[\"target\"] = data.apply(lambda x: [x.Speaker_Status]*x.n_sent, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDSCjNfrBsBO"
      },
      "source": [
        "\n",
        "target = sum(data[\"target\"].tolist(), [])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQQTjZrtCjFs",
        "outputId": "18f50bad-24b4-494a-e29c-d09cc5125566"
      },
      "source": [
        "len(target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13823"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk6aAJIbCk5B"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sents, target,  test_size = 0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rid3OpHcC4n5"
      },
      "source": [
        "cntvec2 = CountVectorizer(tokenizer=custom_tokenizer)\n",
        "train_cntvec = cntvec2.fit_transform(X_train)\n",
        "test_cntvec = cntvec2.transform(X_test)\n",
        "\n",
        "clf = SGDClassifier(random_state=0)\n",
        "clf.fit(train_cntvec, y_train)\n",
        "\n",
        "train_res.loc[\"sentence\", \"stem\"].at[\"countvec\"] = np.round(accuracy_score(clf.predict(train_cntvec), y_train), decimals=3)\n",
        "test_res.loc[\"sentence\", \"stem\"].at[\"countvec\"] = np.round(accuracy_score(clf.predict(test_cntvec), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gYjZr8IDGtO"
      },
      "source": [
        "cntvec3 = CountVectorizer(tokenizer=custom_tokenizer)\n",
        "train_cntvec = cntvec3.fit_transform(X_train)\n",
        "test_cntvec = cntvec3.transform(X_test)\n",
        "\n",
        "clf = SGDClassifier(random_state=0)\n",
        "clf.fit(train_cntvec, y_train)\n",
        "\n",
        "train_res.loc[\"sentence\", \"lem\"].at[\"countvec\"] = np.round(accuracy_score(clf.predict(train_cntvec), y_train), decimals=3)\n",
        "test_res.loc[\"sentence\", \"lem\"].at[\"countvec\"] = np.round(accuracy_score(clf.predict(test_cntvec), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6CKRlhwDQDB"
      },
      "source": [
        "tfidf2 = TfidfVectorizer(tokenizer=custom_tokenizer, max_df=.9)\n",
        "train_tfidf = tfidf2.fit_transform(X_train)\n",
        "test_tfidf = tfidf2.transform(X_test)\n",
        "\n",
        "clf1 = SGDClassifier(random_state=0)\n",
        "clf1.fit(train_tfidf, y_train)\n",
        "\n",
        "train_res.loc[\"sentence\", \"stem\"].at[\"tf-idf\"] = np.round(accuracy_score(clf1.predict(train_tfidf), y_train), decimals=3)\n",
        "test_res.loc[\"sentence\", \"stem\"].at[\"tf-idf\"] = np.round(accuracy_score(clf1.predict(test_tfidf), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdvQ_e9eDP3A"
      },
      "source": [
        "tfidf3 = TfidfVectorizer(tokenizer=custom_lemmatizer, max_df=.9)\n",
        "train_tfidf = tfidf3.fit_transform(X_train)\n",
        "test_tfidf = tfidf3.transform(X_test)\n",
        "\n",
        "clf1 = SGDClassifier(random_state=0)\n",
        "clf1.fit(train_tfidf, y_train)\n",
        "\n",
        "train_res.loc[\"sentence\", \"lem\"].at[\"tf-idf\"] = np.round(accuracy_score(clf1.predict(train_tfidf), y_train), decimals=3)\n",
        "test_res.loc[\"sentence\", \"lem\"].at[\"tf-idf\"] = np.round(accuracy_score(clf1.predict(test_tfidf), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7uAgcu4DPlv",
        "outputId": "5f750653-a978-41b1-d96a-3670241d8821"
      },
      "source": [
        "hash_vec2 = HashingVectorizer(tokenizer=custom_tokenizer, n_features=10000)\n",
        "train_hash = hash_vec2.fit_transform(X_train)\n",
        "test_hash = hash_vec2.transform(X_test)\n",
        "\n",
        "clf2 = SGDClassifier(random_state=0)\n",
        "clf2.fit(train_hash, y_train)\n",
        "\n",
        "train_res.loc[\"sentence\", \"stem\"].at[\"hashing\"] = np.round(accuracy_score(clf2.predict(train_hash), y_train), decimals=3)\n",
        "test_res.loc[\"sentence\", \"stem\"].at[\"hashing\"] = np.round(accuracy_score(clf2.predict(test_hash), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6OgssOrDPMl",
        "outputId": "61c3db28-0e1f-4b59-c44f-bf3aaec08f9a"
      },
      "source": [
        "hash_vec3 = HashingVectorizer(tokenizer=custom_lemmatizer, n_features=10000)\n",
        "train_hash = hash_vec3.fit_transform(X_train)\n",
        "test_hash = hash_vec3.transform(X_test)\n",
        "\n",
        "clf2 = SGDClassifier(random_state=0)\n",
        "clf2.fit(train_hash, y_train)\n",
        "\n",
        "train_res.loc[\"sentence\", \"lem\"].at[\"hashing\"] = np.round(accuracy_score(clf2.predict(train_hash), y_train), decimals=3)\n",
        "test_res.loc[\"sentence\", \"lem\"].at[\"hashing\"] = np.round(accuracy_score(clf2.predict(test_hash), y_test), decimals=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "08AfhUGHD9QX",
        "outputId": "3f4d57e9-d4c7-4f0a-a16c-f8cf85ff4332"
      },
      "source": [
        "train_res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>countvec</th>\n",
              "      <th>tf-idf</th>\n",
              "      <th>hashing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">phrase</th>\n",
              "      <th>lem</th>\n",
              "      <td>0.848</td>\n",
              "      <td>0.804</td>\n",
              "      <td>0.751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem</th>\n",
              "      <td>0.846</td>\n",
              "      <td>0.806</td>\n",
              "      <td>0.746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">sentence</th>\n",
              "      <th>lem</th>\n",
              "      <td>0.771</td>\n",
              "      <td>0.724</td>\n",
              "      <td>0.688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem</th>\n",
              "      <td>0.771</td>\n",
              "      <td>0.726</td>\n",
              "      <td>0.693</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              countvec tf-idf hashing\n",
              "phrase   lem     0.848  0.804   0.751\n",
              "         stem    0.846  0.806   0.746\n",
              "sentence lem     0.771  0.724   0.688\n",
              "         stem    0.771  0.726   0.693"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "XtRkLjrCD_-6",
        "outputId": "3c6db158-7af6-4c9a-f925-ddcc2c451cb8"
      },
      "source": [
        "test_res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>countvec</th>\n",
              "      <th>tf-idf</th>\n",
              "      <th>hashing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">phrase</th>\n",
              "      <th>lem</th>\n",
              "      <td>0.622</td>\n",
              "      <td>0.651</td>\n",
              "      <td>0.657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem</th>\n",
              "      <td>0.62</td>\n",
              "      <td>0.652</td>\n",
              "      <td>0.656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">sentence</th>\n",
              "      <th>lem</th>\n",
              "      <td>0.651</td>\n",
              "      <td>0.665</td>\n",
              "      <td>0.655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stem</th>\n",
              "      <td>0.651</td>\n",
              "      <td>0.661</td>\n",
              "      <td>0.663</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              countvec tf-idf hashing\n",
              "phrase   lem     0.622  0.651   0.657\n",
              "         stem     0.62  0.652   0.656\n",
              "sentence lem     0.651  0.665   0.655\n",
              "         stem    0.651  0.661   0.663"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T75Rn5E1ENDV",
        "outputId": "d5d3e366-00e7-4fb2-ff25-dd7d4597a6ee"
      },
      "source": [
        "clf2.predict(train_hash)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NON-P', 'PRINCESS', 'NON-P', ..., 'NON-P', 'NON-P', 'PRINCESS'],\n",
              "      dtype='<U8')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    }
  ]
}